{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Finding Lane Lines on the Road** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "In this notebook I built a lane line detection pipeline for highway driving video image.  \n",
    "Final output image is below.\n",
    "<img src=\"examples/laneLines_thirdPass.jpg\" width=\"480\" alt=\"Combined Image\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Lane Detection Pipeline\n",
    "Some OpenCV functions (beyond those introduced in the lesson) that might be useful for this project are:\n",
    "\n",
    "`cv2.inRange()` for color selection  \n",
    "`cv2.fillPoly()` for regions selection  \n",
    "`cv2.line()` to draw lines on an image given endpoints  \n",
    "`cv2.addWeighted()` to coadd / overlay two images  \n",
    "`cv2.cvtColor()` to grayscale or change color  \n",
    "`cv2.imwrite()` to output images to file  \n",
    "`cv2.bitwise_and()` to apply a mask to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    return cv2.bitwise_and(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "\n",
    "# (1)Gray Scaled\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# (2)Gaussian Blur\n",
    "blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "# (3)Canny Edge Detection\n",
    "canny = cv2.Canny(blur, 100, 120)\n",
    "\n",
    "# (4)Masked unrelated area\n",
    "masked = mask(canny, np.array([[(0, canny.shape[0]), (canny.shape[1]/2, 300), (canny.shape[1], canny.shape[0])]], dtype=np.int32))\n",
    "\n",
    "lines = cv2.HoughLinesP(masked, 1, np.pi/180, 30, 5, 5)\n",
    "S = (lines[:,:,3] - lines[:,:,1]) / (lines[:,:,2] - lines[:,:,0]) # slope\n",
    "I = lines[:,:,1] - S * lines[:,:,0] # intercept\n",
    "\n",
    "# (5)Hough Drawed\n",
    "hough_drawed = np.zeros((canny.shape[0], canny.shape[1], 3), dtype=np.uint8)\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(hough_drawed, (x1, y1), (x2, y2), [0,255,0], 2)\n",
    "    \n",
    "# (6)Hough Averaged\n",
    "right = (S > 0.0).flatten()\n",
    "left = (S < 0.0).flatten()\n",
    "\n",
    "slope_r = S[right].mean()\n",
    "intercept_r = I[right].mean()\n",
    "\n",
    "slope_l = S[left].mean()\n",
    "intercept_l = I[left].mean()\n",
    "\n",
    "right_x = np.append(lines[:,:,0][right].flatten(), lines[:,:,2][right].flatten())\n",
    "right_y = np.append(lines[:,:,1][right].flatten(), lines[:,:,3][right].flatten())\n",
    "left_x = np.append(lines[:,:,0][left].flatten(), lines[:,:,2][left].flatten())\n",
    "left_y = np.append(lines[:,:,1][left].flatten(), lines[:,:,3][left].flatten())\n",
    "\n",
    "xr1 = np.min(right_x)\n",
    "yr1 = np.min(right_y)\n",
    "yr2 = image.shape[0]\n",
    "xr2 = int((yr2-intercept_r) / slope_r)\n",
    "\n",
    "yl1 = image.shape[0]\n",
    "xl1 = int((yl1-intercept_l) / np.mean(slope_l))\n",
    "xl2 = np.max(left_x)\n",
    "yl2 = np.min(left_y)\n",
    "\n",
    "result = np.zeros_like(hough_drawed)\n",
    "cv2.line(result, (xr1, yr1), (xr2, yr2), [0, 255, 0], 4)\n",
    "cv2.line(result, (xl1, yl1), (xl2, yl2), [0, 255, 0], 4)\n",
    "\n",
    "print(\"Right:\\t\", slope_r, intercept_r)\n",
    "print(\"Left: \\t\", slope_l, intercept_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the way to detect lanes\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(3,2,1)\n",
    "plt.title(\"(1)Gray Scaled\")\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.subplot(3,2,2)\n",
    "plt.title(\"(2)Gaussian Blur\")\n",
    "plt.imshow(blur, cmap='gray')\n",
    "plt.subplot(3,2,3)\n",
    "plt.title(\"(3)Canny Edge\")\n",
    "plt.imshow(canny, cmap='gray')\n",
    "plt.subplot(3,2,4)\n",
    "plt.title(\"(4)Area Masked\")\n",
    "plt.imshow(masked, cmap='gray')\n",
    "plt.subplot(3,2,5)\n",
    "plt.title(\"(5)Hough Line\")\n",
    "plt.imshow(hough_drawed)\n",
    "plt.subplot(3,2,6)\n",
    "plt.title(\"(6)Averaged\")\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The program of this cell is not used. (I just want to keep my idea.)\n",
    "# To cut off outliers of hough line I tried clustering.\n",
    "\n",
    "#clusters = KMeans(n_clusters=2).fit_predict(np.abs(S))\n",
    "#lane_line_cluster = 1 if np.mean(clusters) > 0.5 else 0\n",
    "#not_noise = (clusters == lane_line_cluster)\n",
    "#right = (S < 0.0).flatten()\n",
    "#left = (S > 0.0).flatten()\n",
    "#S_right = S[not_noise*right]\n",
    "#S_left = S[not_noise*left]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Lane Finding Pipeline\n",
    "To allpy above algorighm to video images I build a function as an interface.  \n",
    "The program is almost same as above. The differende:\n",
    " - Step5 was cut off.\n",
    " - Add a process which overlays line drawed image to original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    global global_slope_r, global_slope_l\n",
    "    global global_intercept_r, global_intercept_l\n",
    "    global xr1, yr1, xl2, yl2\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    canny = cv2.Canny(blur, 100, 120)\n",
    "    masked = mask(canny, np.array([[(0, canny.shape[0]), (canny.shape[1]/2, 300), (canny.shape[1], canny.shape[0])]], dtype=np.int32))\n",
    "    \n",
    "    lines = cv2.HoughLinesP(masked, 1, np.pi/180, 30, 5, 5)\n",
    "    S = (lines[:,:,3] - lines[:,:,1]) / (lines[:,:,2] - lines[:,:,0]) # slopes\n",
    "    I = lines[:,:,1] - S * lines[:,:,0] # intercepts\n",
    "    \n",
    "    right = (S > 0.0).flatten()\n",
    "    left = (S < 0.0).flatten()\n",
    "    \n",
    "    global_slope_r = global_slope_r * 0.8 + S[right].mean() * 0.2\n",
    "    global_slope_l = global_slope_l * 0.8 + S[left].mean() * 0.2\n",
    "    global_intercept_r = global_intercept_r * 0.8 + I[right].mean() * 0.2\n",
    "    global_intercept_l = global_intercept_l * 0.8 + I[left].mean() * 0.2\n",
    "    #print(global_slope_r, '\\t', global_slope_l, '\\t', global_intercept_r, '\\t', global_intercept_l)\n",
    "    \n",
    "    right_x = np.append(lines[:,:,0][right].flatten(), lines[:,:,2][right].flatten())\n",
    "    right_y = np.append(lines[:,:,1][right].flatten(), lines[:,:,3][right].flatten())\n",
    "    left_x = np.append(lines[:,:,0][left].flatten(), lines[:,:,2][left].flatten())\n",
    "    left_y = np.append(lines[:,:,1][left].flatten(), lines[:,:,3][left].flatten())\n",
    "    \n",
    "    xr1 = int(xr1 * 0.7 + np.min(right_x) * 0.3) if np.min(right_x) > xl2 + 5 else xr1\n",
    "    yr1 = int(yr1 * 0.8 + np.min(right_y) * 0.2)\n",
    "    yr2 = image.shape[0]\n",
    "    xr2 = int((yr2-global_intercept_r) / global_slope_r)\n",
    "    \n",
    "    yl1 = image.shape[0]\n",
    "    xl1 = int((yl1-global_intercept_l) / global_slope_l)\n",
    "    xl2 = int(xl2 * 0.7 + np.max(left_x) * 0.3) if np.max(left_x) < xr1 - 5 else xl2\n",
    "    yl2 = int(yl2 * 0.8 + np.min(left_y) * 0.2)\n",
    "    #print(xr1, '\\t', yr1, '\\t', xl2, '\\t', yl2)\n",
    "    \n",
    "    result = np.zeros_like(image)\n",
    "    cv2.line(result, (xr1, yr1), (xr2, yr2), [255, 0, 0], 6)\n",
    "    cv2.line(result, (xl1, yl1), (xl2, yl2), [255, 0, 0], 6)\n",
    "    \n",
    "    return cv2.addWeighted(image, 0.8, result, 1., 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Algorithm with Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_images = os.listdir(\"test_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = mpimg.imread('test_images/{}'.format(test_images[3]))\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(process_image(test_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw on Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████▋| 221/222 [00:02<00:00, 107.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "\n",
    "global_slope_r = 0.6379401735626508\n",
    "global_slope_l = -0.5299387574062713\n",
    "global_intercept_r = -0.7090874664852213\n",
    "global_intercept_l = 646.7096210703668\n",
    "xr1 = 502\n",
    "yr1 = 318\n",
    "xl2 = 467\n",
    "yl2 = 316\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the one with the solid yellow lane on the left. This one's more tricky!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solid_yellow_left.mp4\n",
      "[MoviePy] Writing video test_videos_output/solid_yellow_left.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████▉| 681/682 [00:05<00:00, 115.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solid_yellow_left.mp4 \n",
      "\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solid_yellow_left.mp4'\n",
    "\n",
    "global_slope_r = 0.6379401735626508\n",
    "global_slope_l = -0.5299387574062713\n",
    "global_intercept_r = -0.7090874664852213\n",
    "global_intercept_l = 646.7096210703668\n",
    "xr1 = 502\n",
    "yr1 = 318\n",
    "xl2 = 467\n",
    "yl2 = 316\n",
    "\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "##clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solid_yellow_left.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "##clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(0,5)\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clear this optional challenge I need to transform color space."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
